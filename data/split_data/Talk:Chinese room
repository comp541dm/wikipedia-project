Need to say that some people think that Searle is saying there are limits to how intelligently computers can behave;;Similarly, some people also lump Searle in with Dreyfus, Penrose and others who have said that there are limits to what AI can achieve. This also will require some research, because Searle is rarely crystal clear about this. This belongs in a footnote to the section '''Strong AI vs. AI research'''. ---- CharlesGillingham (talk) 21:37, 10 February 2011 (UTC):He seems clear enough to me:  he doesn't claim that there are limits on computer behavior, only that there are limits on what can be inferred from that behavior. Looie496 (talk) 23:24, 5 April 2011 (UTC)::Yes, I think so too, but I have a strong feeling that there are some people who have written entire papers that were motivated by the assumption that Searle was saying that AI would never succeed in creating "human level intelligence". I think these papers are misguided, as I take it you do. Nevertheless, I think they exist, so we might want to mention them. ---- CharlesGillingham (talk) 08:19, 6 April 2011 (UTC):::Is this the same as asking if computers can ''understand'', or that there are limits to their understanding? What does it mean to limit intelligence, or intelligent behaviour? Myrvin (talk) 10:16, 6 April 2011 (UTC):::There is eg. this paraphrase of Searle: "Adding a few lines of code cannot give intelligence to an unintelliget system. Therefore, we cannot hope to program a computer to exhibit understanding." Arbib ; Hesse, ''The construction of reality'' p. 29. Myrvin (talk) 13:19, 6 April 2011 (UTC)::::I think that, even in this quote, Searle still holds that there is a distinction between "real" intelligence and "simulated" intelligence. He accepts that "simulated" intelligence is possible. So the article always needs to make a clear distinction between intelligent '''behavior''' (which Searle thinks is possible) and "real" intelligence and understanding (which he does not think is possible).::::The article covers this interpretation. The source is Russell and Norvig, the leading AI textbook.::::What the article doesn't have is a source that disagrees with this interpretation: i.e. a source that thinks that Searle is saying there are limits to how much ''simulated'' intelligent ''behavior'' that a machine can demonstrate. I don't have this source, but I'm pretty sure it exists somewhere. ---- CharlesGillingham (talk) 17:32, 6 April 2011 (UTC)::::Oops! I responded thinking that the quote came from Searle. Sorry if that was confusing. Perhaps Arbib ; Hesse are the source I was looking for. Do they believe that Searle is saying there are limits to how intelligent a machine can behave? ---- CharlesGillingham (talk) 07:34, 7 April 2011 (UTC):::See what you think CG. It's in Google books at: . Myrvin (talk) 08:27, 7 April 2011 (UTC)::::Reading that quote one more time, I think that A;H do disagree with the article. They say (Searle says) a computer can't "'''''exhibit''''' understanding". Russell and Norvig disagree (I think). They say (Searle says) even if a computer can "exhibit" understanding, this doesn't mean that it actually understands.::::With this issue, it's really difficult to tell the difference between these two positions from out-of-context quotes. If the writer isn't fully cognizant of the issue, they will tend to write sentences that can be read either way. ---- CharlesGillingham (talk) 19:27, 12 April 2011 (UTC)What am I missing?Luizpuodzius (talk) 23:23, 23 September 2015 (UTC)Where I agree and disagree with SearleLooie496 (talk) 12:35, 22 September 2015 (UTC)Richard Yee source(ref 51, 59, 60) Department of Computer Science, University of Massachusetts at Amherst. His  is published in [Lyceum], which seems to be a free online journal published by the ''Saint Anselm Philosophy Club''. Can't find much on him, apart from a few papers presented at workshops ("Machine learning: Proceedings of the Eighth International Workshop (ML91)"),  "Abstraction in Control Learning".Is there any reason to believe this person and his opinion are notable? His argument seems to be superfluous, imo, it doesn't add anything. We know that the instructions (the "rules table") are the program. The room has only one set of instructions: for Chinese. There's no talk about the room doing other languages ("changing the program"). In all aspects it is a general turing machine doing one specific task. Yet Yee brings up external programs and universal turing machines, only to say they are a red herring and "philosophical discussions about "computers" should focus on general Turing computability without the distraction of universal programmability.". A distraction he himself introduced.We're not supposed to interpret sources, but it makes me wonder whether his paper/opinion is really more notable than for example a random blog entry or forum post discussing the subject. The point he makes would already be obvious to the reader: the rules table, not the person, is the program. Yet this is once again repeated in the systems reply section with an example, concluding: ''Yet, now we know two things: (1) the computation of integer addition is actually occurring in the room and (2) the person is not the primary thing responsible for it.'' This was first added . Is it really necessary to explain it at such length? User:Ssscienccce|Ssscienccce ;/font; (talk) 02:43, 7 October 2015 (UTC):I agree. It's the naive "system" reply, with a little formal window dressing.:I think he's kind of missed the point about the room being a Turing machine -- the point is, digital computers can never be "more sentient" than the room-with-Searle, they can only be faster. The Chinese room is as sentient as you ever get. ---- CharlesGillingham (talk) 05:26, 14 December 2015 (UTC)
Was the analytical engine ever built?The history of computers page says that the analytical engine was never built, this page at least implies that it was. Which is correct? .Charles Babbage:It was never built. His son built a part of it (arithmetical unit and printer) which  the most important control unit which would make it programmable. I'll clarify that. --AxelBoldt:As far as I understand, his son build a 4-function calculator with printer by his own design (derived from Babbage's mill). And Babbage did build part of the mill including the printer, but this is a different machine. The latter can be recognized as having many horizontal racks in it and several cam wheels in front of it.SvenPB 14:43, 5 September 2005 (UTC)This page states that the analytical engine was a hundred years ahead of comperable...computers. Were there other computer at the time of the analytical engine? Or was it the technological equivalent of computers that would be built a century later?   --rmhermen:There were no other computers at the time. The first comparable ones appeared 100 years later. --AxelBoldt:The key to Babbage's idea was to seperate calculation and memory. This was only reinvented a century later. In Babbage's time non-programmable calculators were build. Schickard's and Leibniz' machines could multiply. Schickard used the principle of Napier's bones. Leibniz used the principle of the stepped drum. And Schultz actually build a difference machine in Babbage's time. Babbage and Schultz have also met. Schultz' machine looks ok, but as I understand it was not very well thought out and didn't work very well (for example the position of the wheels wasn't defined. Babbage's used springs for that. In general Babbage's machines are not matched by any other design from a mechanical point of view).SvenPB 14:38, 5 September 2005 (UTC)----100 years after 1837 (first description) or 1871 (death)? Are you referring to Zuse? --YoodenMechanical DrawingsDoes anyone know where I might find plans of either engine?BrentB''Plans which would be useful to a machinist are non-existant.  The site linked in the article provides sufficient detail for designing a new machine that functions under the principles of the Analytical and Difference engines.  The Science Museum in London, England currently has in it's archives the design sketches which Babbage produced within his lifetime.  These are substantially complement, however they only provide a description of the parts and their relationships.  These would need to be translated into dimensioned drawings to fabricate actual parts.  A difficult process, but one which is very doable, and one that I am attempting to perform at the moment.  Still figuring out how to talk to the museum's archive department and obtain full-scale reproductions of the necessary docs.'' -- wackyvorlonI wonder if they ever will become available online or in print. Maybe Google will scan them. I know many professional drawings have been made of the machines and also thousands of pages of sketches are in existence. Though, as wackyvorlon remarks, they can not be translated to metal directly.SvenPB 14:28, 5 September 2005 (UTC)Ada Byron's involvement.I removed the following sentence from the start of the Design paragraph "ada byron was the real inventer. ". It is unsourced, not formatted and clearly (to me) spam. If anyone can prove otherwise, find a source and feel free to stick the sentence back in. Spacerat3004 19:00, 27 May 2007 (UTC):You are exactly right - Ada had nothing to do with the design of the machine.  Her involvement was mostly in translating and adding clarifying notes about the machine.  Her main innovation (and there is some debate about whether even that was hers) was on the software side of things.  Her notes describe things that modern programmers would recognise as loops, subroutines and libraries - and as far as we know, she was the first person ever to write about such things.  So certainly it is wildly incorrect to say that Ada was the real inventor of the Analytical engine - it might be correct to say that she is the inventor of many of the constructs of modern programming languages - but even that is a matter of some debate.  I really feel for Ada - she must have been the most frustrated programmer in history!  Having all of those great ideas for how to program a computer - but no computer to actually run them on! SteveBaker 20:34, 27 May 2007 (UTC):'''The''' statement was part of vandalism by an IP (see ). You should have just reverted to the previous version. I have now restored the deleted content. -- Petri Krohn 05:15, 8 June 2007 (UTC)NegativeThis is a very negative article, which fails to reflect the problems that Babbage would have found himself up against.Chasnor15 (talk) 16:59, 4 April 2008 (UTC): ...such as...?  What?  SteveBaker (talk) 03:00, 6 May 2008 (UTC)Bold in First Paragraph?Do we need those statements in the first paragraph to be bolded? I think that it makes the article seem sensational and that there is no need to emphasise them.Davidedmeades (talk) 21:21, 30 January 2009 (UTC)Random noteApplying moores law from the three minute estimate, and assuming that it applies from 1971, would give a 1941 descendant of a babbage engine a calculating time of about 5 nanoseconds. ahead of a modern pc.. in the 1940s  —Preceding unsigned comment added by Special:Contributions/118.93.86.50|118.93.86.50 (talk) 08:56, 24 November 2009 (UTC);; ;;Was the analytical engine ever built?The top of the page blames Babbage for being 'disagreeable' and for 'alienating his machinist'  The reference provided says nothing about Babbage alienating his machinist.  According to more studied texts, Babbage's machinist was a Scotsman who saw the project as a source of income rather than taking it seriously.  It was an unfortunate match up.  The machinist cut parts to beyond tolerance required, and appears to have over charged.  When funding ran out, the machinist left with all of his tools, which was very damaging for the project.  Law suits found that the tools indeed belonged to the machinist as in those day without a contract saying otherwise that was the rule.  I'm sure the machinist found great use in tools for building difference engines...   It is unprofessional for a machinist to over charge independent of the temperament of the contractor.  There are a number of indicators it is the machinist who was difficult to work with, not the other way around.  Serious literature on Babbage's work place fault on failure of the project on a combination of the lobbying work of the head of the government navigation table 'calculators' office against further funding, the over billing practices of the machinist, and the fact it really was an expensive machine (the government spent about the price of steam locomotive on it),  and where was the private funding?.  -- due to the reference not saying what we are told it says I am removing this part about alienating the machinist.  Someone would do us a favor to put in more information with proper references about the lobbying against the machine by the calculators and the over billing on the part of the machinist.  Tom Lynch (www.linkedin.com/in/ThomasWLynch)  —Preceding unsigned comment added by Special:Contributions/188.61.105.195|188.61.105.195 (talk) 22:14, 7 February 2010 (UTC);; ;;influencethis section is inaccurate.  Babbage's work was known in Europe, affected a design that came out of Sweden and no doubt was subsumed into the large industry that came about for mechanical calculators that surpassed he simple Pascaline.  Howard Aiken cited Babbage as an inspiration for the Mark Machines.   Henry Provost Babbage built parts of Babbage's machines, and published on them (~1875).   I do not know why this myth that Babbage's machines were 'lost' persists in so many writings today.   I will add the bit about Henry to the article.  Tom Lynch (www.linkedin.com/in/ThomasWLynch).  —Preceding unsigned comment added by Special:Contributions/188.61.105.195|188.61.105.195 (talk) 22:38, 7 February 2010 (UTC);; ;;John Graham-Cumming/Plan 28: Project to build Charles Babbage's Analytical EngineIt was announced on "this week in Tech" that there is currently a fund raising effort to try to get the Analytical engine built.  It is being put together by John Graham-Cumming under the name "Project 28".  Should an reference to this be included in the article or a link be provided? WalterFletcherIV (talk) 05:41, 13 October 2010 (UTC)More at: "It's time to build the Analytical Engine" by John Graham-Cumming - Bevo (talk) 20:43, 13 October 2010 (UTC)My preference would be to see if this project takes hold before it gets mention in the article itself.  Otherwise it would appear that the article is being used to solicit sponsors for the project.  This section in the Discussion page should be sufficient for now until something substantive develops. - Bevo (talk) 20:43, 13 October 2010 (UTC)After an impressive 'sign up' and awareness start in but only a few days, it is widely felt that inclusion of the AE construction proposal is now valid and reasonable. Naturally it should be modified and added to as needed in the Wikipedia 'style'. I hear the point raised by Bevo above re: article is being used to solicit sponsors for the project, but much of the interest in Babbage and the AE in general is connected with ''could it have been built? would it have worked?'' etc. This proposal seeks to answer these questions and naturally will no doubt fascinate the casual reader. Thus despite some concerns, on balance, plan28 ideas should be included. The Superintelligence (talk) 15:41, 16 October 2010 (UTC):I'm not so sure. According to - as of today (Jan 22nd 2011) only 4,000 people have pledged their $10.  The manifesto of the Plan 28 team says that they need 10,000 pledges by the end of January...but looking at the sign-up rate after an initial rush of enthusiasm in the first few weeks, the growth rate of pledges has been down at below 100 per week.  At this rate it'll take 4 years to get to the line - and they only have just over a week.  Worse still, the Plan 28 website says that they need 50,000 to sign up - not 10,000 as Pledge Bank suggests.  However, as of Dec 11th, John Graham-Cumming said that he's in negotiations with one or more commercial backers - so it's still perfectly possible that this could happen - despite lack-lustre support from the masses. SteveBaker (talk) 21:34, 22 January 2011 (UTC)Sourcesthe references for this page suck. The only good one is the science museum. number 3 does not work. It suggests the mill of the analytical engine was a difference engine curved in on its self. Well show me your wordpress page with sources if your going to say that. Thats a potent statement.  —Preceding unsigned comment added by Special:Contributions/67.86.127.105|67.86.127.105 (talk) 17:15, 26 November 2010 (UTC);; ;;Discussion of whether Analytical engine was an important historical step.;lt;''Moved from User talk:SteveBaker - the text under discussion is from the first sentence of the lede which says: "'''an important step in the history of computers,'''" '';gt;Hi Steve.  Regarding this reversion,  it's the words "important step" that I have a problem with.  A "step" implies--actually, more than implies--specifies--a necessary event in a sequence of events, a link in a causal chain.  The developers of electronic digital computers in the 1940s that led to the computers we have today were unaware of Babbage.  Given this, had Babbage never existed, history would've been the same.  The analytical engine cannot be classified as an "important step"--it's more of a fascinating footnote, discovered after-the-fact.  I won't revert right away but will give you time to respond or else make the reversion yourself.  If you would to have further discussion on this and bring in others, feel free to move this to the article talk page. User:Robert K S|RobertKS (talk) 20:40, 22 January 2011 (UTC): I completely agree that Babbage's work had little, if any, influence on the '''development''' of subsequent computers - but how can you possibly maintain that the first ever concept of a stored program machine is not an important '''historical''' point?  The text that you removed, and I reverted, says exactly that.  It is hard, perhaps impossible, to find any book or article on the history of computing that doesn't describe the Analytical Engine as an important historical event...and that's all that this statement in our article says.  If we were talking about an important step in the '''development''' of modern computers - then I'd agree completely with you - but we're not, so I don't.: If you still can't accept that - then we'll need to continue this discussion further - and, as always, we'll need a consensus to change the status quo.  I would appreciate if you did not re-remove those words until/unless there is reasonable consensus to do so.: SteveBaker (talk) 21:00, 22 January 2011 (UTC)::Well, it really doesn't matter whether you or I think the Analytical Engine was important or not.  Such a determination is a judgment, a point of view.  You can see how WP:NPOV would bar such a thing from being placed in the article, and especially so prominently in the lead.  Why not stick to the facts, and let the reader determine how important the Analytical Engine was?  The fact that this point is controversial--at least between you and I, to say nothing of the larger community of computer historians--is only a further reason for eliminating this unnecessary phrase, and not really the primary reason.  Let's keep this article neutral in tone. User:Robert K S|RobertKS (talk) 21:38, 22 January 2011 (UTC)::: It is a fact (verifiable in dozens and dozens of books and articles - pick almost any one) that the Analytical engine is considered to be an important step in the '''history''' of computers.  You seem to be consistently making the error of assuming that we're saying that the Analytical engine was important in the '''design''' of subsequent machines - which it clearly was not.  (Incidentally, your careful definition of the word "step" is not born out by any of several dictionaries that I have consulted.  Wiktionary's closest definition is: "''The space passed over by one movement of the foot in walking or running. Used also figuratively of any kind of progress.''".  There is no definition that I can find that says that a "step" is a necessary event in a sequence of events.  Indeed, a step can lead to a dead end...as it did here.)::: What has been controversial between computer historians is whether this was something that influenced subsequent computer development (although, I have to say that this controversy has largely vanished of late - it is fairly clear that nobody who subsequently designed a computer based their work on the ideas that Babbage set forth).  But we're not talking about the importance in the '''development''' of computers - we're talking about the importance in their '''history'''...and of that there can be no doubt because just about every history of computers has the Analytical engine right there, front-and-center in chapter one.  Claiming that it's not important to that history belies the writings of every computer historian to have put pen to paper on the subject over the past 30 years.  I don't see any way to defend your position in the face of all of those reliable sources.  The importance of the Analytical engine to this history is a notable and easily verifiable fact. SteveBaker (talk) 22:46, 22 January 2011 (UTC)::::(1) That something is "important" can never be a fact.  It is a value judgment.  ''Who'' has made this value judgment?  ''When''?  ''Why'' or for what reasons?  Is there some dispute about value judgment?  (2) If a step leads to a dead end, how can it be an important one?  If the analytical engine was not an important "step" in the development of computers, how and why is it an important "step" in the history of computers? User:Robert K S|RobertKS (talk) 23:40, 22 January 2011 (UTC)::::: Nonsense!  We can say that something is "important" if enough reliable sources say that it is.  Are you really saying that no Wikipedia article can ever describe anything as "important"?  That's just nuts!  In this case, pretty much all of the reliable-source accounts of the history of computing clearly point to the importance of this historical event.  That also answers the "Who" and "When" questions - and frequently the "Why" also.  When there is near unanimity about some event's importance, it would be wrong NOT to report that here.::::: Steps that lead to dead ends are often important - that's often the only way you find out that you're heading in the wrong direction - it doesn't take much imagination to come up with examples of that.  You seem REALLY desperate to make this argument - but I'm not seeing a single thing to say that the Analytical Engine wasn't an important step in the history of computing - so why the heck are you making such a big deal of it?  Like it or not - this is not some small footnote in the history of computers - and that's not just my opinion.  Just crack open any book on the history of computing. SteveBaker (talk) 01:48, 23 January 2011 (UTC)::::::This article, as all other articles, must follow WP:ATTRIBUTEPOV when assigning value judgments.  "Important" isn't an objective statement but a subjective evaluation.  "Joe DiMaggio holds the Major League Baseball hitting streak record with hits in 56 consecutive games" (an objective statement) is different from "Joe DiMaggio was a great baseball player" (a subjective statement).  Which reference "clearly point[s] to the importance of" the non-construction of the machine plan of a single man working alone?  How was the Analytical Engine of historical importance to the history of computing?  Earnestly answer my sincere questions instead of arguing and insisting.  With regard to the argument that "[s]teps that lead to dead ends are often important" because "that's often the only way you find out that you're heading in the wrong direction", this does not apply to the Analytical engine.  Babbage's design was not a case of trial and error, a machine with a flaw that became evident and led to an improvement (as was the case with ENIAC, which lacked a large, fast memory to hold a stored program and led to the EDVAC).  As the article points out, there is consensus that, if built, it would have worked according to its specifications; furthermore, no person followed Babbage who built a mechanical computer by improving upon Babbage's design. User:Robert K S|RobertKS (talk) 02:07, 23 January 2011 (UTC)::::::: May I strongly suggest you go and read some of the fine references we have here.  In fact there were many machines built following Babbage designs - some of them were improvements - some used ideas from the Analytical engine's simplified 'mill' design rather than the inferior Difference engine mechanisms.  I recommend "The Cogwheel Brain" by Doron Swade.  None of those machines were specifically "analytical engine" spin-offs - but most certainly many of Babbages ideas were turned into working hardware by other people.  Not only is it possible that the Analytical engine would have worked - but there are a group of people at the Science Museum in London who have studied the design sufficiently to understand it - and are currently attempting to get the funding to build one.::::::: It is unnecessary to explain to you, here in this talk page, what the importance of the Analytical engine is historically.  We do not come here to teach history - we come to edit an encyclopedia.  It is sufficient to mention pretty much any reliable source on the history of computing and point to the part that talks about the Analytical engine.  A design that was not "important" wouldn't get that much coverage by the historical sources.  Let's go with the ones I happen to have on my bookshelf right now::::::::* Computers: The Life Story of a Technology by Swedin and Ferro:::::::* The First Computers--History and Architectures (History of Computing) by Hashagen and Rojas:::::::* Communications and Computers (History of Invention) by Chris Woodford::::::: All of these books describe the Analytical engine as historically important and each spends a good fraction of a chapter discussing it.  I didn't have to pick these three books - I'm very confident that any history of computing published within the last 30 years will cover the Analytical engine.  Since the statement that you are edit-warring over is not generally a controversial one - we would not normally bother to provide a reference for it in the article.  If you'd like to claim that this IS a controversial point - then I'd be happy to add a pointless blue number next to that statement with a link to one of these (or MANY other) books. SteveBaker (talk) 03:32, 23 January 2011 (UTC):::::::: I didn't think it was a controversial point, but you are making me wonder.  The statement that the analytical engine was "an important step in the history of computers" implies that the Analytical engine led in some way to modern computers, whereas it did not.  Of the references you list, I have only Rojas on hand (you reverse the authors, by the way).  In that book, there are chapters about many early computers, but none predating the 1930s, and there is no chapter on the analytical engine.  Babbage is not even listed in the index.  There is a brief subsection relevant to Babbage starting on page 43 in the paper by Williams, but the conclusion reached is supportive of the position that the Analytical engine was not "an important step": "...the Babbage engines were of no great interest before the success of the Mark I moved Howard Aiken to identify them as a general source of inspiration..."  With my apologies, I do respectfully insist, per WP:V and WP:BURDEN, along with the guidelines previously cited, and for the good of the article, that this "importance" business be properly attributed and sourced.  No hand waving. User:Robert K S|RobertKS (talk) 04:22, 23 January 2011 (UTC)I have (again) reverted the first sentence of the lede to it's previous form.  Please do NOT continue to edit war over this.  The civilized way to work for change in the event of an editing dispute is to put the article back to it's original form (as I have done) and seek consensus to change it.  Until there has been reasonable discussion here involving other editors - repeatedly changing the article to how you want it to be in the hope that you'll run out the 3RR and everyone will give up and let you get away with it is unacceptable behavior.  Let us have a proper consensus debate before the article's lede is changed again.  If it turns out that you're right - then you'll get your change soon enough. SteveBaker (talk) 03:10, 23 January 2011 (UTC):Following WP:BRD, the first time you reverted my change, rather than revert your reversion, I posted to your talk page and offered you the opportunity to present a case.  What you offered were unsubstantiated assertions and a mistaken view of Wikipedia guidelines.  That the analytical engine was a notable development is not in dispute.  That a subjective assertion about its "importance" should not be in the article's lead should be beyond dispute.  I'll wait a few days for comment from others, and after that, if no one has commented, I will raise the issue on WP:3. Best, User:Robert K S|RobertKS (talk) 03:39, 23 January 2011 (UTC)::To be accurate, you made the change, I objected and reverted.  You posted to my talk page to request a discussion and I readily agreed to that, even going so far as to start the discussion here and copy your post over to get it started...'''THEN''', without any consensus whatever and without even waiting politely for other interested parties to join the discussion - you replaced your change!!  That is just rude.  This is not a change of an urgent nature, nobody is being offended or getting sued over it - you can await consensus before making your change.  SteveBaker (talk) 03:45, 23 January 2011 (UTC):::The case I've made under WP:ATTRIBUTEPOV is sufficient for removal of the offending phrase.  To give the impression that the Analytical engine sparked interest in computing that was diligently pursued, making it "an important step" in the march of history, is to promote bad history.  Instead, Babbage's work was all but forgotten, then resurrected as a historical curiosity ("Wow, look at what this guy did!  He invented so many things that had to be reinvented for modern computers!"--or, as Aiken is [said] to have exclaimed about Babbage, "if he had just lived 75 years later he would have scooped me!"). User:Robert K S|RobertKS (talk) 04:37, 23 January 2011 (UTC)I am with SteveBaker on this. Wikipedia documents what other people say - it does not perform original research. Wizzy;hellip;User talk:Wizzy|''';#9742;''';/big; 07:06, 23 January 2011 (UTC):If Wikipedia documents what others say, how could you be with Steve Baker?  Where do others say that Babbage is "an important step in the history of computers"? User:Robert K S|RobertKS (talk) 07:50, 23 January 2011 (UTC)::In more or less every reliable source on the subject of the history of computers...duh! SteveBaker (talk) 14:36, 24 January 2011 (UTC):::More flippancy and hand-waving where quotation and citation is what is needed. Best, User:Robert K S|RobertKS (talk) 17:04, 24 January 2011 (UTC)::::Babbage has only ''belatedly'' been dubbed Father of the Computer ref. Halacy, Daniel Stephen (1970). ''Charles Babbage, Father of the Computer''. In the same way, the importance of his analytical engine is evident ''now'' though it was not ''then''. History is a record of steps which are actions towards a goal, but are not necessarily individually successful nor causally connected with an actual route to success. We can say that Babbage's engine was an important step in the history of computers in the same way that [Leonado da Vinci's helicopter] was an important step in the history of heavier-than-air flight, notwithstanding the fact that it never flew. Cuddlyable3 (talk) 20:41, 24 January 2011 (UTC):::: I'm not near my bookshelves at the moment - so I'll just grab a statement at random from one of the bazillion similar books.  From Google Books:::::  says: "Modern writers have generally viewed the machine as an important intellectual step toward the stored program electronic computer.":::: The fact is that '''EVERY''' single book that I open that talks about the history of computing - from "My first illustrated computer - a popup book" (ages 5 through 7) to the seven volume monster work "History of Computing" by Denley, Hopkin et-al mentions the Analytical Engine.  Not a single one of these history books leave it out of the story on the grounds that it's not important.  There are conference proceedings on the topic of the history of computing that have multiple papers about the machine (eg History of Computing:Learning from the Past: IFIP WG 9.7 by Arthur Tatnall), there are TV documentaries - recreations in museums...).  That clearly indicates "historical importance".  You can't seriously be claiming that there are no references to back this up?! SteveBaker (talk) 21:21, 24 January 2011 (UTC):::::I agree that "Babbage's engine was an important step in the history of computers in the same way that Leonardo da Vinci's helicopter was an important step in the history of heavier-than-air flight".  Just as the history of heavier-than-air flight did not depend on da Vinci, the development of functional computers did not depend on Babbage.  I have never said that Babbage has no historical "importance".  But notability is self-evident to the reader from the mere fact that the article exists in the encyclopedia (non-notable subjects do not get their own articles).  I am disputing that the Analytical Engine was "an important step in the history of computers".  It was not.  And you will not find a reference that says that it was.  You will only find your own subjective opinion, which does not meet the threshold for inclusion.  User:Robert K S|RobertKS (talk) 23:38, 24 January 2011 (UTC)::::::Go and read WP:NOTE - "notability" is not the same thing as "importance"...and especially not the same thing as "historical importance".  How can you possibly assert that I won't find a reference that says "''the Analytical Engine was an important step in the history of computers''" - when about three lines up from where you wrote that, I have provided a reference that says: "''Modern writers have generally viewed the machine as an important intellectual step toward the stored program electronic computer.''"!!  I even provided a link to the Google Books page where it may be found in order that you can verify that I'm not misquoting it or quoting it out of context.  Anyway - all of this is unimportant.  It's quite clear that you don't have any kind of consensus for your change - so I strongly suggest that you drop this argument and let us all move on to other, more important, matters.  SteveBaker (talk) 05:50, 25 January 2011 (UTC)::::::Go and read WP:NOTE - "notability" is not the same thing as "importance"...and especially not the same thing as "historical importance".  How can you possibly assert that I won't find a reference that says "''the Analytical Engine was an important step in the history of computers''" - when about three lines up from where you wrote that, I have provided a reference that says: "''Modern writers have generally viewed the machine as an important intellectual step toward the stored program electronic computer.''"!!  I even provided a link to the Google Books page where it may be found in order that you can verify that I'm not misquoting it or quoting it out of context.  Anyway - all of this is unimportant.  It's quite clear that you don't have any kind of consensus for your change - so I strongly suggest that you drop this argument and let us all move on to other, more important, matters.  SteveBaker (talk) 05:50, 25 January 2011 (UTC)I have to agree with SteveBaker, here - ''important'' is an accurate summary of the relevant sources. The rest of the lead and article explain the context. Further, it has the utility to our readers of linking history of computers right off. RobertKS - would it address your concerns to put a brief sentence at the end of the first paragraph (after ''the engine was never built'') to the effect that the designs were largely forgotten and not used in the design of Colossus '';c.''? - User talk:2over0|2/0 (Special:Contributions/2over0|cont.);14:35, 25 January 2011 (UTC):The problem here is still WP:ATTRIBUTEPOV.  We don't put subjective statements on Wikipedia without attributing them.  SteveBaker presents the Grier book which provides a similar (but not identical) statement to the one he's seeking to preserve, and that statement in itself is not even offered as the author's own, with reasoned support, but is instead offered with the same vague wave of the hands: "Modern writers have generally viewed..."  This leaves the statement unevaluatable, unamenable to editorial review (which is surprising given that Grier is a former editor of the ''Annals'').  It is not a verifiable statement from a reliable source, suitable for inclusion on Wikipedia, it's hearsay.  Still, it gives us something: it permits us to write, "According to computer historian David Alan Grier, modern writers view the machine as an important intellectual step in the history of computers."  This is still rather weak--a double attribution?--through Grier, then through unspecified "modern writers"?  Also, many writers dispute this summary, including Williams in Rojas as cited in the discussion above, or, for example, Doron Swade in the 2001 book ''The Difference Engine'' ("Babbage's influence on modern computing may not be as strong as popular perception"--which I read as a tactful way of saying, Babbage had no influence on modern computing, which is the reality).  Really, if there is any kind of academic controversy over Babbage's influence (and I didn't think that there was--I thought that most people understood perfectly well that Babbage was a modern rediscovery of something old and cool, sort of like like the Antikythera mechanism) then, you know, we ought to have a section about that in the article somewhere, and give it proper treatment.  To stuff it into the lead, and sort of dust our hands off and say, "There, we've done our job!", well, that would be abdication our of job, in fact.  But in no instance should we be printing (or reprinting) subjective statements without proper attribution.  We would never write "George Washington was an important president" or "Tom Hanks is an important actor".  Besides being devoid of factual content, such a statement, unattributed, is unevaluatable, at best a naked assertion that leaves the reader relying on faith, and at worst, bunkum. User:Robert K S|RobertKS (talk) 23:58, 25 January 2011 (UTC)Would anyone involved in the present dispute object to my changing "step" to "milestone"?--Father Goose (talk) 07:28, 28 January 2011 (UTC):How does that address the issue I am raising?  The words "step" and "milestone" are synonymous.  It doesn't solve the issue of unattributed POV, and the statement would still be a false or misleading one. User:Robert K S|RobertKS (talk) 11:55, 28 January 2011 (UTC)"Milestone" per Father Goose works for me.  Andrew S. Tanenbaum's book "Structured Computer Organization" calls it one.[ftp://ftp.prenhall.com/pub/esm/the_apt_series.s-042/tanenbaum/sample_chapter/x1.pdf]  "Development" also seems ok.  I think Robert K S is going the wrong way on several fronts.  First, "influence on modern computing" and "important milestone in the history of computing" are not the same thing.  The article linked  discusses the issue at length.  The history of computing includes the intellectual history and not just the development of hardware.  The analytical engine's importance in the history of computing is attested by the prominence that every book about the history of computing gives to it.  For example, H. H. Goldstine devotes the first chapter of "The Computer from Pascal to von Neumann" to it.  Second, the analytical engine's influence on later computers is well-established, for example the article talks about Howard Aiken and the Mark I.    [Here] is another article describing a less direct influence.  I think it can be useful to discuss these issues further down in the article, but overall I think Robert K S's arguments about the lede are bordering on tendentious.  Special:Contributions/71.141.88.54|71.141.88.54 (talk) 04:40, 30 January 2011 (UTC): "step" and "milestone" are more or less synonyms in this context.  If you consider this to be some kind of a compromise - then it's fine by me, but I really don't think it matters.  We have a pretty solid consensus for the present wording. SteveBaker (talk) 05:02, 30 January 2011 (UTC)::Well, I don't see them as quite synomous; a milestone is something that's simply ''there'', whether or not one happens to walk past it.  Also, "milestone" is sourceable (to Tanenbaum) if that helps.   BTW, 532109 is a review of "The Cogwheel Brain" that while favorable describes the book as "somewhat revisionist".  Certainly the article should present viewpoints from it. Special:Contributions/71.141.88.54|71.141.88.54 (talk) 05:07, 30 January 2011 (UTC):"the analytical engine's influence on later computers is well-established" -- that's a cloudier issue than it initially seems.  Reading through various works on Google Books ()::* "Randell concludes that if Aiken 'had known more about the Analytical Engine, he would surely have included conditional branch facilities in the original design of the Mark I.'  Most of the restropective discussions in print concerning Mark I generally stress this limitation.":* "Reviewing all the evidence, and taking Aiken's oral testimony at face value, one would have to conclude that Babbage did not play a major role in the development of Aiken's ideas about machine architecture.":* "It is also clear, however, that Aiken was not strongly influenced by the details of Babbage's work.":* The best assessment of this question in regard to Aiken is by the historian of science I. Bernard Cohen, who concludes that while Aiken's admiration for Babbage was great, his actual knowledge of the Analytical Engine was superficial.":*"When Aiken was still a graduate student, he 'set forth' his 'proposals' for a new kind of calculating machine." "In Aiken's words, Lanza just 'couldn't see why in the world I wanted to do anything like this in the Physics Laboratory, because we already had such a machine and nobody used it."  "There, 'sure enough' Aiken told us, were the wheels [of Babbage's engine]..." "This was the first time Aiken 'ever heard of Babbage'.":*"There is no evidence that Aiken declared indebtedness to Babbage for any particular features of his own inventions.  Rather, it seems, Aiken praised Babbage to in order to enhance his own stature.":What this communicates is that Aiken's design for the Mark I wasn't heavily influenced by the Analytical Engine, and that he was already trying to build a computer before he was even aware of Babbage's work.  The above sources point out that Aiken was a great admirer of Babbage, and that he took pains to credit Babbage as his precursor.  But the inspiration was not technical so much as perhaps emotional: he was emboldened by Babbage's work, and used its existence to add authority to his proposals.:The article, as presently written, paints a somewhat misleading picture on these points, I would say.  It would be good to rewrite it a bit to clarify what Babbage's influence was on Aiken and the Mark I.--Father Goose (talk) 08:58, 30 January 2011 (UTC):: Thank you, Father Goose, for the references. I think ''milestone'' is appropriate, as it properly reflects the place given to Babbage in historical literature, without claiming direct parentage. Wizzy;hellip;User talk:Wizzy|''';#9742;''';/big; 09:41, 30 January 2011 (UTC):::Father Goose is muddying the waters.  Yes, the claim that "''the analytical engine's influence on later computers is well-established''" is highly dubious - and I certainly wouldn't want to say anything remotely like that in our article, and certainly not in the lede where it would have to be stated without adequate discussion.  Older books sometimes say that Babbage and Ada Lovelace had a huge influence ("The father of computing", "The world's first programmer", etc) - but modern researchers largely indicate that this influence on later computers was very small - perhaps even zero.  The evidence (eg in "The Cogwheel Brain") is that most of the early computer designers were either entirely unaware of Babbages' work - or didn't see it as relevant to what they were doing.  The fact that many features of modern computers are so stunningly similar to the Analytical engine appears to be more a matter of "convergent evolution" than of direct influence.::: '''''But''''';/big; '''we aren't arguing about whether the designs of later computers were influenced by Babbage or not''' - the question is whether the Analytical engine was "'''an important historical step'''".  The proof of '''that''' is everywhere!  Just about every book on the history of computers talks about this machine - so it's clearly spectacularly important to computer historians - and that's exactly what our article says.::: Those same books often talk about the abacus - and recent ones about the Antikythera mechanism - which makes those two inventions also "important historical steps".  But very few 20th century computers used either base 10 arithmetic or the particular carry mechanism that an abacus uses - let alone the idea of moving an object from one place to another to count, so the abacus really had zero influence on computer design.  We only recently realized what the heck the Antikythera mechanism was - and we're still not 100% sure how it worked - so we know for sure that it had no influence whatever on computer design.  Yet the abacus, Antikythera and the Analytical engine all get prominent mention right there in chapter one of all of these books.  Historical importance is clearly not correlated with direct influence on design.::: This is purely a question of the importance '''to history'''.  Let us not confuse the issue with talk of whether early electronic hardware had Babbages ideas built into them.::: SteveBaker (talk) 14:52, 30 January 2011 (UTC)::::I'm not denying its historical importance.  If anything, I would emphasize it more than the article already does.  Babbage's accomplishment was nothing short of astonishing -- how often is a person 100 years ahead of his time?::::But clarification is called for specifically with respect to its influence on later machines.  At least a couple of us feel that some of the wording in the article conveys the sense that it directly influenced the design of later machines.  Some modest changes to the wording could fix that.--Father Goose (talk) 19:39, 30 January 2011 (UTC):::::I agree that we need to say something about that other question - so let's draw a line under this discussion and start a new section...::::: SteveBaker (talk) 22:27, 30 January 2011 (UTC)What should we say about Babbages' influence on subsequent computer design?I think we should try to say something about this - if only to "deflate" the notion that all modern computers owe their existence to Babbages' work...which is certainly not the case.  I think the section in "The Cogwheel Brain" on this is probably the most authoritative source on this. We already have a section under "Influence/Computer Science" - but it doesn't mention any influence (or lack thereof) on modern computers. SteveBaker (talk) 22:27, 30 January 2011 (UTC):I started work on a more general rewrite: .  I wasn't thrilled with the lead as it was before... I felt it somehow just didn't capture what was so special about the analytical engine.  It also had various details, such as the Science Museum's construction of the difference engine, that was more suited to later sections of the article.:So far I've left the "influence" question untouched.  I'll make an attempt to rewrite that section next, provided this first set of changes doesn't drag us into a different set of conflicts.--Father Goose (talk) 05:43, 1 February 2011 (UTC)::I reverted your addition to the influence section (sorry!) because that machine was not an "analytical" engine (ie a programmable computer) but a "difference" engine (ie a mindless calculator of mathematical tables that used the mathematical "Method of Differences" technique).  There were several other difference engines built over the years.  They were influenced by Babbages Difference engine - but none of them attempted to be programmable in any way - and hence are more like calculators than computers.  At any rate, they didn't show influence from the Analytical engine - and hence are inappropriate to discuss here because the suggest that the Analytical engine had contemporary influence...which it did not.  SteveBaker (talk) 13:07, 1 February 2011 (UTC):::Fair enough.  It's difficult to isolate one from the other because their fates were both the same, as a result of largely the same influences.  I wanted to mention the Scheutz engine because the article talks about the Science Museum's engine for the purpose of explaining that building at least that machine wasn't an impossibility in his time -- the Scheutz engine even demonstrates that a comparable machine ''was'' built in his time.--Father Goose (talk) 22:44, 1 February 2011 (UTC):: I like much of your rewrite - but it suffers from some of the same problem as your last actual edit here.  Again, this is '''NOT''' an article about Babbage's work in general - and it is specifically '''NOT''' about his "Difference engine" design - we have a completely separate article about that.  The Analytical engine wasn't stopped due to "inadequate" funding - that was the Difference engine.  The Analytical engine was never funded at all (I suppose, technically "no funding at all" counts as "inadequate" - but that word hardly gets the message across).  Also, the arguments with Babbages engineer were to do with the Difference engine.  The machine that the Science Museum in London built from Babbage's plan is the Difference engine - and it has little relevance to the Analytical engine - apart, perhaps, from demonstrating that Babbages' design wasn't impossible to build with Victorian tools and the precision and repeatability of parts that the Victorians would have been able to provide.  We must be very careful to keep these two machines entirely separate in our reader's minds because they are commonly confused.  Aside from the fact that they both used gear wheels to do arithmetic, they are otherwise entirely unrelated.  In fact, the arithmetic part of the Analytical engine (the "mill") would have done arithmetic in a completely different manner to the Difference engine.:: When talking about causes of the failure of Babbage to realize the design of either machine as a working prototype, I don't think it's entirely fair to place the blame with funding and his engineering staff.   It was his habit to repeatedly change the design - so rapidly that the drawings couldn't keep up.  That was undoubtedly one source of frustration for his engineers - and it was probably just as much his fault as theirs that the relationship fell apart.   A similar issue arises with funding.  He did, initially, get a pile of money from the government to build his difference engine - and it was only his repeated failure to meet deadlines and come up with actual working hardware because of his repeated design revisions that made them leery of giving him more money.  His interactions with the government were downright hostile - he wrote entire books that were rudely critical of them - and then was surprised when they wouldn't give him more money!:: Babbage may have been a genius when it came to mechanical "engines" - but he was terrible at interpersonal relationships, project management and dealing with government departments.  Most of the reasons for failure have to be laid at his feet - because others who came later were able to build complete (albeit somewhat simplified) difference engines.:: If we try to keep the "blame" section on-topic and talk only about the Analytical engine, then we should talk about other issues than funding and his ability to work with his team.:: The problem with the Analytical engine (as a realizable design) was that he VASTLY over-scoped it.  Why on earth did he demand 50 decimal digits of precision?  That's around 170 bits of precision (in modern terms) - when the PC at your desk has only 64 bits - and a perfectly usable microprocessor was built with only 4 bits!  There are very few calculations that the Victorians would have cared about that would have needed more than maybe 8 decimal digits.  He even built a "double precision" mode into the machine that would have produced 100 decimal digits!!  Similarly, he planned an ungodly amount of memory for the machine - much more than early practical computers.  Given that each digit in each storage location required a bunch of mechanical "stuff", that was a really poor decision.:: Modern engineers would certainly try to build the minimum possible size of machine as "proof of concept" that would show off all of its features.  Had Babbage designed a more modest four digit-precision machine with maybe a dozen memory locations - he could almost certainly have demonstrated all of the incredible things that the machine could do using funding he could have afforded from his own pocket.  But demanding the money to build the behemoth that he planned without having something to demonstrate the value of the machine was doomed to failure.:: Another interesting failure (relating to the Difference engine - but likely also at issue with the Analytical engine too) was Babbages' lack of thought about how the machine would be lubricated - and how it could be repaired in the event of problems.  His lack of practical experience with these machines might have been resolved had the Difference engine every come to fruition - but because that was never finished, he hadn't learned those necessary lessons as he designed this gargantuan machine.  The guys who built the replica Difference engine found that the nature of the interlocking mechanism made it impossible to remove just one column of gears in order to adjust a part or replace something that broke (something that happened a lot during construction) - instead you had to dismantle more or less the entire machine in order to fix one small issue.  At the scale of the Difference engine, that was bad enough - but at the planned scale of the Analytical engine, it would have been a nightmare scenario.:: SteveBaker (talk) 13:55, 1 February 2011 (UTC):::All right, the article can do more to avoid conflating the two machines.  But their fates were definitely intertwined.  Much of what can be said about the failure to construct the analytical engine derives from, or at least is illustrated by, his failures with the difference engine -- technical, financial, interpersonal.:::I would be happy to document Babbage's role in the falling-out with Clement, but the sources I've come across only vaguely allude to it.  If you could point me to a source that details these troubles, I could make further improvements -- or you could too, ahem.:::Your points about lubrication and repair difficulty might also have some place in this article (and definitely in difference engine), but again, you have to identify sources before we can do anything with it.--Father Goose (talk) 22:44, 1 February 2011 (UTC)::::In both cases, "The Cogwheel Brain" by Doron Swade (who runs the Computer history section of the London Science museum - where all of Babbages papers are held and where they reconstructed the Difference engine).  My son has my copy right now - when I get it back I can look up some specific refs. SteveBaker (talk) 00:05, 2 February 2011 (UTC):All right, I've edited the paragraphs regarding Aiken to better reflect what the available sources say.  I removed the bits about Stibitz, since I can't find any actual connection between his work and Babbage's.  I also decided remove the sentence about Torres and Bush -- too unspecific and uncited anyway.:That leaves us with the half sentence that was the start of the earlier dispute: "an important step in the history of computers".  I personally think it's unnecessary, especially given the tweaks I made to the lead.  It's a bit peacocky and I think it breaks up the flow of the first sentence.  I'm hoping that the revised lead does the trick of explaining the Engine's importance and place in the history of computing, and as for the link to history of computing, we now have the navbox on the right and a link to history of computing hardware under the text "the first general-purpose computers".--Father Goose (talk) 06:43, 2 February 2011 (UTC)::It's been 48 hours, so I'll ask the question again... do we need that half sentence in the lead?--Father Goose (talk) 04:28, 4 February 2011 (UTC):::Thanks for your work. I think we can lose it. Wizzy;hellip;User talk:Wizzy|''';#9742;''';/big; 17:24, 4 February 2011 (UTC):::I dunno - we just went through all of that consensus-building to keep it!   SteveBaker (talk) 20:06, 4 February 2011 (UTC)::::What consensus building? User:Robert K S|RobertKS (talk) 22:05, 4 February 2011 (UTC):::::Meanwhile, Robert, are there any remaining concerns you have with the article aside from the half sentence presently being discussed?--Father Goose (talk) 00:25, 6 February 2011 (UTC)::::::I will answer in a new section below. User:Robert K S|RobertKS (talk) 01:32, 6 February 2011 (UTC)::::Please be specific about why you want to keep it; I have offered my thinking as to why I feel it is no longer necessary.--Father Goose (talk) 01:19, 5 February 2011 (UTC)Reconstruction NewsIt looks like  is now on the way to building a replica Analytical engine - with a goal to complete it by 2021. SteveBaker (talk) 00:05, 2 February 2011 (UTC)Whoops!In searching for sources for some of the statements in the article, I came across , which appears to have plagiarized this article.  The text in question was present in this article before the book's 2007 publication.--Father Goose (talk) 05:18, 2 February 2011 (UTC): "The '''''free''''' encyclopedia"...so long as he credited Wikipedia per the terms of GFDL, that's actually perfectly OK (I don't think we were using CC-BY-SA 3 back then though). SteveBaker (talk) 11:09, 2 February 2011 (UTC)::I see nothing to indicate that the author did credit us.  Not that there's any action we can take anyway.  Still, that's the first time I've seen our work plagiarized in a book.--Father Goose (talk) 11:18, 2 February 2011 (UTC):::It happens quite a lot actually.  But if you're sure there is no credit given per GFDL then the correct action would be as outlined at Wikipedia:Mirrors_and_forks#Non-compliance_process (although that leans heavily towards websites that plagiarize without giving credit).  However, note that the only person who can do this is the person(s) who wrote the text that was infringed.  Wikipedia doesn't own the copyright on the content submitted by our editors!  However, if you can find someone who contributed to the 2007-ish version of the article that was plagiarized - then they should send one of those letters to the publisher of the book.  If one of the original authors were to pursue it, it's possible that they could sue the publisher or the author. SteveBaker (talk) 12:45, 2 February 2011 (UTC)Latest version of article after Father Goose revisions (as of 2011-02-05)Here are some notes on the article as it now stands:* Summing up the first paragraph of the lead is this remark: "...making it the first Turing complete design for a general-purpose computer".  For maximal accessibility we would do well to avoid using a technically abstruse term like "Turing-complete" in a lead paragraph.  This term is not well-known or understood by a general reader and requires further explication.  IMO the wording found in an earlier version of the lead was closer to the mark: a better substitute would probably be something like, "In its architecture, the design for the analytical engine anticipated the critical features of the first completed general-purpose computers by about 100 years."  This is, really, the significant thing about the analytical engine--not that it contributed to the evolution of computers but that, lo and behold, here was this thing that was ahead of its time, and it took us a century to realize by just how much, and the whole thing needed to be re-invented.  I don't have a problem with coming back to the "Turing complete" designation later in the article, where it can perhaps be better explained.By the way, "Turing complete" is unhyphenated where it should be here, but later in the article, hyphenated where it shouldn't be, and later still, unhyphenated where it should be!* The lead has somehow lost the critical information that "Babbage continued to refine the design until his death in 1871" and thus now implies by omission that the design was frozen in 1837.  Any good lead should tell the who-what-when-where-why-and-how, and the "when" question in this case cannot be answered by a single point but requires a range of dates, i.e., at least two dates.* The sentence "Babbage was never able to complete construction of any of his machines due to conflicts with his chief engineer and inadequate funding" seems an inadequate condensation of the reasons for Babbage's failure to produce a working model of the analytical engine, which, as a survey of the literature will show, is a debate that remains controversial.  I can't propose a specific improvement, except to say that I thought the old lead's version of this summary was a little better.  Father Goose's version may have been informed by a desire to make every assertion in the lead footnote-ref-able.  This is not strictly required in the lead.  A lead should be a summary or a synthesis of the information in the article.  To write a poor summary or synthesis because of perceived WP:V constraints is to unjustifiably hinder the article.* To the same end, I thought the concluding sentences of the old lead were also worth keeping."A partial construction of one of Babbage's machines was done by his son Henry and also more recently the construction of one of his simpler designs was done by the British Science Museum. Indications are today that the machine could have been built successfully with the technology of the era if funding and political support had been stronger."* Probably, the second sentence of first paragraph of the "Design" section could be axed completely to the benefit of the article.  It is sufficient for this article to note that Babbage conceived the analytical engine while he was thinking about the difference engine, and, perhaps, what the differences between the two designs were.  The reasons for the difference engine's failure are outside the scope of this article.Overriding principle here is "get to the point".* "Later drawings depict a regularized grid layout" should not be a parenthetical because the "Initially" of the previous sentence commands it to follow (unparenthetically).* "...she has been described as the first computer programmer" is an unattributed opinion.  ("By whom?")* "The modern computer programming language Ada is named in her honour" is trivia to this article.  It is proper to the Countess Lovelace article and not to this one.* Did Henry Babbage know that the pi computation was faulty, or was that a modern determination?  Confusing parenthetical.  Also, at end of this paragraph, missing a period.* A question that remains in my mind after reading the article is why, despite all the thought that went into the conception, Babbage did not think to use floating-point arithmetic.* In "Computer science" section, Aiken is confusingly introduced twice, as if by a memoryless writer.  The rest of the portions on Aiken are inadequate, incompletely describing the controversy extant in the literature over "What did Howard know and when did he know it?"  There is no explanation why, if Aiken knew of and had studied Babbage, he did not design the Mark I to have the functionality of Babbage (e.g., to include loops and subroutines and therefore to create in the Mark I a true computer rather than as just a calculator capable of proceeding along a linear set of instructions). The reference to the "1930s" during which Aiken is said to have discovered Babbage's work is too vague (can't we pin this down a little better)?* The finger of influence between Babbage's "rod-logic" and molecular computers' "rod-logic" is incompletely drawn.  Did the molecular computer designers in question intentionally try to emulate Babbage, or is this section merely describing a coincidental similarity noticed after-the-fact?* The Babbage quote at the end of the influence section is contextless as reprinted here.  Actually, it is worse than contextless.  It is placed in the wrong context.  What Babbage meant when he said that is that scientists and mathematicians with access to a computing machine like the analytical engine would be able to progress in their work in ways not previously possible, to such an extent that the faces of these fields would be indelibly changed.The ENIAC creators made similar predictions.  See, e.g.,  ''New York Times'' article.  Babbage did not mean that his machine would influence future computer developments, and especially he did not mean that his machine would influence future high-speed electronic computing developments, since he did not foresee electronics.  But this section is about the machine's influence on later computers, not Babbage's prediction of the machine's influence on science and math.* Long lists of shout-outs in fiction are generally disallowed on Wikipedia.  I won't be the one to delete/pare this section, as I am not a deletionist, but any deletionist worth his salt would identify it as WP:LISTCRUFT.  Any time I have worked on content like this on the encyclopedia, somebody else has come along and deleted it.* The top paragraph of the "Comparison" section should be revised to eliminate the double "however".  There needs to be a citation for the Moore's Law assertion.* I question how useful the 1940s computers comparison table is here when it does not permit easy comparison to the analytical engine.  If it is not removed, at least a paragraph should be placed above it that essentially re-creates a top row of the table for the analytical engine.* And, of course, for all the many reasons I elaborated earlier and for a few that I've come to understand since then, the "important step" nonsense has got to go.Thanks for listening, User:Robert K S|RobertKS (talk) 02:45, 6 February 2011 (UTC)----:"Turing complete" is both a nice short way of saying "a computer that can solve anything or simulate anything" and also a simple technical checklist for identifying whether a computer does meet that description.  Your suggestion is better than what was there before I edited it, but it's still too vague for my tastes.  I want to know what those critical features are -- and as it turns out, they're the Turing three.  It had very little in common with modern machines -- other than those specific algorithmic qualities, but they're the ones that count.:I'm also not sure the term is as problematic for laymen as you make it out to be -- it's not hard to guess that the term is some technically specific way of saying "a complete computer".  I do agree with you that beyond its basic meaning, it is a oft-misused term; the article Turing completeness is a mess I don't want to touch.  But perhaps we should take a swing at giving a basic explanation of it in this article.  I admit I was trying to dodge that bullet in my first pass of the rewrite.:"Continued to refine it until his death" -- that somewhat contradicted one of the sources I came across, but I've since come across , which supports it.  (That source also gives good info about Henry's efforts and the BA's rejection of it in 1878.)  I'm not as convinced as you that it's a detail that needs to be in the lead, but if it does belong in there, I think it works better in the second paragraph instead of the first, in keeping with a more or less chronological order.:You're right that I oversimplified the reasons for the machine not being constructed.  Right now I'm waiting on Steve filling in some of that info from ''Cogwheel Brain''.:Something halfway in between my edits to the lead and the text in your third footnote might be best.:I don't agree that we should remove all details about the difference engine from this article.  As I said in my earlier discussions with Steve, the reasons behind the failure to construct the difference engine seem to have doomed the analytical engine as well.  But the second sentence in the "design" section is if nothing else in the wrong place.  I'm waiting on the info from ''Cogwheel Brain'' to know what to do with it.:Punctuation tweaks: go ahead.:"The first computer programmer":  is your friend.  I don't mind including the sentence about Ada being named after her; it does relate at least tangentially because the work she with regards to the engine caused that honor to be bestowed upon her.:Faulty pi computation: good question.  One of us needs to do the research.  Hint hint.:Floating point: I'd hazard a guess that fixed-point arithmetic would work just as well and was simpler.  You can do floating point on an integer ALU through software anyway. Lots of modern embedded CPUs still don't have it.  It's only been built into PCs since the 486 onward.:Aiken: go ahead and fill those details in.  Most of them are found within the sources already given.  But it drifts into the problem you're highlighting elsewhere -- it doesn't relate a whole lot to the analytical engine.:Rod-logic: I agree.  Someone will have to do more research to answer those questions.  I also agree about the Babbage quote, though I'm content to leave it in its current place until someone actually adds the proper context and moves it to the proper place.:The fiction section: I personally believe that deletionism is completely wrong-headed, so I'm not inclined to imitate them.  Moore's Law: that's a real apples-to-oranges comparison, so I'm just going to remove it outright, which also solves the double-however.:Comparison table: I've cut it down to a representative sample of early computers and added a row for the analytical engine.:--Father Goose (talk) 10:12, 6 February 2011 (UTC)::Thanks, of course, for all your replies.  Defining Turing-complete as "a computer that can solve anything or simulate anything" is, of course, incorrect in its simplicity, highlighting the danger of using such a term: when even someone who knows what they're talking about says something so wrong, we know we have a problem.  Turing's whole thesis was that some problems are uncomputable.  A Turing-complete computer, then, "can solve anything ''that can be solved'' or simulate anything ''that can be simulated''".  (What are "the Turing three"?)  I can say that the analytical engine, if built, was a digital machine (many early computers, up through the 1930s, were analog, e.g. the differential analyzer); could do loops and subroutines (by going backwards and forwards through its card stacks); separated its arithmetical unit (mill) from its memory (store) (even in the ENIAC these were combined in the accumulators); would've been capable of printing (and plotting?) output (an extremely advanced innovation?); and would've used punched cards for input of both data and programs, although not in the same kind of card (punched cards were the standard for data and program entry and long-term storage even up through the early 1970s); but did not in any way anticipate the stored program concept (as it did not use the same memory for both data and instructions). User:Robert K S|RobertKS (talk) 17:35, 6 February 2011 (UTC):::I misspoke regarding the "Turing three" -- I was treating memory and the ability to change memory as two separate things, but the standard Turing-completeness definition assumes read+write.  I admit I go quickly out of my depth where computational theory is concerned.:::Anyhow, if there are any changes you suggested above that I didn't object to, by all means, make them.  I'd like to get back into the B portion of the BRD cycle.  And for any stuff where we're still in partial disagreement, suggest or make specific changes so we can hash out our differences.--Father Goose (talk) 06:41, 7 February 2011 (UTC):::: The business of having separate (and non-writable) program storage isn't really a big deal as far as a fundamental capability is concerned.  One could (for example) implement an interpreter for another language using a program that doesn't need to modify itself - or even ever be loaded or unloaded while the computer is running.  Such a program can then execute programs stored in the separate read/write data store - which can themselves be self-modifying, etc.  Many modern computers work that way because (in essence) their 'microcode' sequencer resides in separate program storage.  What we think of as the "machine code" for the computer is in truth merely interpreted by the read-only microcode.  So while it's unfortunate that Babbage didn't take that final step of unifying code and data - we shouldn't denigrate the underlying computational capabilities because of that.  Indeed it is perfectly possible to build a Turing engine on a machine that has neither jump instructions nor conditionals...provided only that at least one memory location is initialised to a known state when the machine is turned on - and that the program can at least automatically restart when it finishes running (eg by using a 'tape loop' to provide it with instructions).:::: There are certainly things that a Turing engine can't solve (for example, it can't solve the halting problem or prove/disprove all possible mathematical theorems in defiance of Godel's theorem).  But it can simulate things out of physics such as atoms and quantum effects - so with sufficient memory and time, it can (in principle) simulate an entire universe.  That being the case, it can certainly compute anything that can possibly be computed by any other means whatever...given that you provide it with enough time and memory.:::: So saying that any Turing-complete machine is "a computer that can solve anything or simulate anything" needs only to be qualified by adding "...anything that can possibly be computed or simulated by any other means".  Certainly that's a caveat - but it's kinda redundant as a restriction.  It's like saying "It's impossible to do something that's impossible"...a circular definition.  What you can't do is say that there is something that a Turing-complete engine can't solve that can be solved by some higher level machine.  In that sense, "Turing-complete" is as good as it gets - although Godel's theorem and things like the halting problem do place hard limits on its capabilities.:::: SteveBaker (talk) 19:08, 20 February 2011 (UTC)Analytical Engine: capitalized?"Analytical Engine" is capitalized in some parts of this article and uncapitalized in the article title and lead.  Which should be conformed to the other?  It seems to me that even if this was never the machine's "name" it has de facto come to be used as such, and therefore we should adopt capitalization.  I'm not sure what the majority of sources do but I'm fairly certain that many of them do capitalize. User:Robert K S|RobertKS (talk) 17:11, 6 February 2011 (UTC):The preponderance of sources on Google Books capitalize the term: .  I believe we should as well.--Father Goose (talk) 23:35, 8 February 2011 (UTC)My rewriteI have rewritten the influence section.  For the record, the Cohen reference says the following about Aiken and Babbage::Page 61: "One of the persistent beliefs about Aiken is that his thoughts on computing and computers, and the design of [Aiken's calculators], were strongly influenced by the concepts and proposals of Charles Babbage."  [text goes on to expose the legend]:Page 69: "Although there seems to be no way to learn the actual date on which Aiken approached the Physics Department and encountered the Babbage wheels, there are some convincing reasons why this event would have occurred in 1937, at about the time when Aiken had written up his formal proposal for IBM and would have had real hope that his machine be built.  The chief reason for this date is that Aiken would surely not have approached the Physics Department with a request for space if he didn't have a real prospect of his dream machine's becoming a reality.  ¶ When he was writing his proposal Aiken's knowledge of Babbage's machines, particularly the Analytical Engine, was severely limited; it was the kind of information gleaned from meager secondary sources [in which the Analytical Engine was treated only summarily] rather than from a reading of Babbage's own writings about his machines, as in his autobiography."  [Continues with evidence in support]:Pages 70-71: "...Baxandall [in his 1926 book ''Calculating Machines and Instruments'', an annotated and illustrated catalogue of the collection ofthe Science Museum] did not stress the fact that Babbage intended to have his machine print out the results directly in molds from which stereotype blocks could be made for printing (thus eliminating errors due to transcription, typesetting, proofreading, and printing).  Aiken did not mention this feature of the Babbage engines; rather, he presented it as his own innovation.":Page 71: "The conlusion to which we are led is that Aiken initially learned about the work of Babbage primarily through [the Baxandall catalogue and a brief article by Ludgate].  It was from these sources that he derived the summary (and somewhat erroneous) statements about Babbage's machines found in his 1937 proposal to IBM.  That Aiken was generally ignorant of Babbage's machines explains the otherwise puzzling fact that, though Aiken continually expressed admiration for his illustrious predecessor, the architecture of [Aiken's calculator] was little influenced by Babbage's architecture.":Pages 71-72: "Reviewing all the evidence, and taking Aiken's oral testimony at its face value, one would have to conclude that Babbage did not play a major role in the development of Aiken's ideas about machine architecture.  By his own account, Aiken came across detailed information on Babbage's Difference Engine and Analytical Engine only after he had completed a general plan for a digital super-calculator of his own and proposed it to Harvard's Physics Department. ¶ There is no evidence that Aiken declared indebtedness to Babbage for any particular features of his own inventions.  Rather, it seems, Aiken praised Babbage in order to enhance his own stature.  By lauding Babbage's intellectual prowess and conceptual achievements, Aiken seems to have been saying in effect that in his bold pioneering effort he, Howard Aiken, was not alone.  He was suggesting that he was in some sense like Babbage: a radical inventor whose stature was not fully appreciated by his contemporaries, a member of a small group of great men (including Pascal and Leibniz) who had pioneered the art of mechanical computation.  By declaring his personal admiration for Babbage, and paying tribute to other illustrious predecessors, Aiken was not immodestly staking his own claim to a place in history. ¶ It also seems that, as he got deeper and deeper into computing, Aiken--fatherless since his early teens--adopted Babbage as a kind of father figure, somewhat as, in earlier days, he had done with the high school teacher who assured him of an education, with Edward Bennett at the University of Wisconsin, and with E. L. Chaffee at Harvard.:Page 68: "I had one last question about Babbage to put to Aiken: Had he ever actually gone to the Science Museum at South Kensington to see any of the Babbage machines?  'I went to the South Kensington Museum after the war,' he replied.  'I stayed with the Comries, and Comrie made arrangements for the museum to be opened up so that I could get to see the Analytical Engine.'  The museum was 'still in a shambles,' but Aiken did get to see the 'mill' of the Analytical Engine (corresponding in its functional role to the CPU of a modern computer)--'and it was,' he said, 'the greatest disappointment of my life.'"I take my answer off the air.  User:Robert K S|RobertKS (talk) 03:47, 9 February 2011 (UTC):Oh, one other thing.  In the Mauchly colloquium talk, Mauchly makes the statement quoted below.  If we can find what he's referring to (the "professional societies", the "some people"), it would be worthwhile adding this, if not to this article's "influence" section (since the Analytical Engine project involved no toolmaking), then perhaps to a counterpart section in the Difference Engine article.  "...[T]here were in later years professional societies who were attesting to the fact that, due to the attempts at construction of a Babbage difference machine and due to the innovations which Clement and his people had embarked on in order to construct what Babbage was starting out to do, that the whole industry of making calculating - not calculating but fine instruments we'll say  - the whole industry of making fine instruments and doing instruments work in England was thereby advanced, that he made a real contribution. Some people thought the money which was spent on the partly complete difference engine was still amply returned to the British government by reason of the fact that the efforts to build this had contributed to the art of fabrication of fine instruments." User:Robert K S|RobertKS (talk) 05:54, 9 February 2011 (UTC)FictionA Logic Named Joe ''is particularly noteworthy as a prediction of massively networked personal computers and their drawbacks, written at a time when computing was in its infancy.'' --Pawyilee (talk) 15:02, 31 May 2011 (UTC)Memory sizeI just fixed the memory size -- check my maths in case I'm wrong.I found the article saying that:There was to be a store (that is, a memory) capable of holding 1,000 numbers of 40 decimal digits each (ca. 1.7 kB).;/blockquote;This seems to be out by a factor of 10. I have changed it to "17 kB".The article "" states that:In his plans Babbage described an Engine with 100 storage locations holding 40 decimal digits each (which is roughly equivalent to 1.7KB).  He even anticipated the need for ever more memory, describing an Engine with 1,000 storage locations (17KB) and external storage (he would have used punched cards where we use disks).;/blockquote;I assume this is where the article got it from, and why it was confused. Here's my maths for the version with 1000 storage locations:\log_{256}(10^{40}) bytes = 16609.6 bytes = 16.22 KiB.So probably (if my maths is correct), it should read 16.2 kB (interpreting kB as kibibytes) ;mdash;MattGiuca (talk) 06:06, 8 February 2012 (UTC).:Using external data storage in the form of punched cards was always a part of his plan - and it's not clear what (if any) limits there might be on the capacity of that.  As for the "RAM" memory in the form of stacks of gearwheels - it all depends on how much of the stuff he might have decided to manufacture.  Since his addressing scheme used 40 decimal digits for the address, he could have addressed more gearwheel memory than the entire mass of the solar system could contain.  So the actual amount that a working engine would have might depend only on how much money a customer would pay for such a thing.  Since the machine was never built, it doesn't really make too much sense to discuss how much memory it had - only the limits of how much it ''could'' have had.  That said, since we have reliable sources for the 100 and 1000 number versions, we should mention both. SteveBaker (talk) 13:23, 8 February 2012 (UTC)Punch card code, digit coding and Baudot codeI did not understand in this article what type of data are stored on puch card, and how.I note that data punch card are five columns. So I assume that each symbol is encoded on five bits, like onthe Baudot code.I am also interested to understand the logic of the Baudot code. I noted that letters of the Baudot code are oriented according to the Gray Code.I do not understand the logic of Baudot code for digits. Is it inherited of previous legacy system?Here is the baudot code for digits:{|class="wikitable" style="text-align:center;"! scope="col" width="15" | Let.;!! scope="col" width="15" | Fig.;!! scope="col" width="15" | V !! scope="col" width="15" | IV !! scope="col" width="0" |  !! scope="col" width="15" | I !! scope="col" width="15" | II !! scope="col" width="15" | III| rowspan=17 |! scope="col" width="15" | Let.;!! scope="col" width="15" | Fig.;!! scope="col" width="15" | V !! scope="col" width="15" | IV !! scope="col" width="0" |  !!scope="col" width="15" | I !! scope="col" width="15" | II !! scope="col" width="15" | III|-| A || 1 ||   ||   |||| ● ||   ||| J || 6 ||   || ● |||| ● ||   |||-| E || 2 ||   ||   ||||   || ● ||| G || 7 ||   || ● ||||   || ● |||-| Y || 3 ||   ||   ||||   ||   || ●| B || 8 ||   || ● ||||   ||   || ●|-| U || 4 ||   ||   |||| ● ||   || ●| C || 9 ||   || ● |||| ● ||   || ●|-| O || 5 ||   ||   |||| ● || ● || ●| D || 0 (10)||   || ● |||| ● || ● || ●|}Article style rewrite for non-specialistsDespite holding a master's degree in administration, I have found most of the language used in the article wholly incomprehensible in that it uses technical terminology reserved for programmers. To make the article accessible to the general public and therefore more of use, I suggest a deep rewrite by laymen by refraining from technical terms. It took me reading the whole article before inferring that the Analytical Engine was basically some sort of calculator.  — Preceding unsigned comment added by Special:Contributions/108.59.70.238|108.59.70.238 (talk) 11:30, 11 December 2012 (UTC);; ;;:If only you had read the first sentence instead, which instantly shows your inference to be completely wrong. It is so much more than a mere calculator – namely a ''general-purpose computer'' (to appreciate the difference, read Calculator#Calculators compared to computers and the illustrative example at Computer#Stored program architecture) –, and you don't have to be a specialist in anything to understand that; you just need general education in English, since the article ''says it explicitly''. I'm at a loss to understand how somebody with such a gross lack of attention if not reading comprehension can achieve a master's degree in anything. In this case, it's clearly the fault of the reader to miss the forest for the trees. There's never a need to read through an entire Wikipedia article to know what it is about because the introduction section provides a handy summary, and while I admit that there are exceptions, i. e., badly written or outright vandalised articles in desperate need of amendment to conform to Wikipedia's encyclopedic standards, this article is not among them, neither now nor at the time when you posted the inquiry – I've checked the article's history to be sure. So the fault lies with the reader this time, not with Wikipedia. --Florian Blaschke (talk) 12:00, 29 July 2013 (UTC)Plan 28 rebuildA group called "Plan 28" has been collecting funds to build a replica Analytical Engine since 2010. This Wikipedia article said "the project is underway". The project has a blog, a Twitter feed, a Facebook page, a mailing list, a T-shirt, and a donation account. What it doesn't have is results.  As of October 2013. no actual design or construction of anything seems to have occurred.  Last press coverage was over a year ago. Updated article accordingly, per WP:CRYSTAL. John Nagle (talk) 20:56, 10 October 2013 (UTC)"Instigonometric functions"What is this word "instigonometric" in the caption of the photo of the punchcards at the beginning of the "Design" section? I have a very limited education and this is far beyond me, but I note that:*It is redlinked.*The Wikipedia has never heard of it. No other instances of the occurrence of this word occur in the Wikipedia (including anywhere else in this article).*Google seems never to have heard of it. A Google search on "Instigonometric - inputting" (to weed out mirrors of this article) returns, essentially, nothing. I am not a Google maven tho and perhaps I am doing this wrong. (Google does give many returns for the word "instigonometric" alone, tho.)*Google Books returns essentially no results for this word appearing in any book, ever.*Neither of the books given as refs for the caption return any results for "instigonometric".I'm wondering if this is perhaps an archaic word, a foreign word, or a typo? Google replies to requests to search on "instigonometric" with "do you mean trigonometric?" so perhaps this is some sort of mangling of the word "trigonometric"? Given the term "instigonometric", Google Translate detects this as Esparanto but is unable to provide an English equivalent. It appears in [this Indonesian-language paper] so I wonder if it is Indonesian? Does "fungsi instigonometric" mean "trigonometric function" in Indonesian and this Indonesian term has somehow gotten into the article?If it's none of these and is real, it seems pretty obscure even for readers who can solve for x, could we replace it with a more accessible term? Herostratus (talk) 12:01, 21 April 2015 (UTC):They might mean trig functions, which can be approximated using polynomials.  --Shanedidona (talk) 04:05, 7 December 2015 (UTC):The image was originally added with this edit , with the caption "Two types of punched cards used to program the machine. Foreground: "operational cards", for inputting instructions; background: "variable cards", for inputting data".  This was changed to (at least roughly) the current text with this edit:  https://en.wikipedia.org/w/index.php?title=Analytical_Engine;diff=prev;oldid=547446881]. in what appears to be vandalism.  I have attempted to put this back together, but given the length of time since the vandalism, I'd appreciate if someone could review.  Rwessel (talk) 06:59, 7 December 2015 (UTC)Number of digits in store/memory wordsThe article says 1000 words of 40 digits, which is what I've heard previously.  The only reference I've been able to see that has a number is the third external link which says 50 digits (the others I've checked are either dead or don't include the word size).  This number has popped up over at Computer program, where apparently the Tanenbaum reference (#6, there), which I also cannot see, says 50 according to another editor.  Some of the earlier discussion on this talk page implies that 40 *was* well referenced.  I'm just hoping to get the inconsistency cleaned up.: Allan G. Bromley (1998). . ''IEEE Annals of the History of Computing'' '''20''':4 says 40 digits. I'd trust that article over what Andy likely mentions in passing (could easily have been a typo, been misremembered, or taken from another source with such a mistake). —''Ruud'' 18:04, 30 October 2015 (UTC):: (BTW the fact that Bromley's article is not used in this article, while several unscrupulous looking websites are, seems a bit worrying to me. —''Ruud'' 18:08, 30 October 2015 (UTC)): Tanenbaum wrote, "The store consisted of 1000 words of 50 decimal digits used to hold variables and results." This sentence is in the section titled, "Milestones in Computer Architecture". However, he also wrote something peculiar in the same section: "Since the analytical engine was programmable in a simple assembly language, it needed software." Of course, "words (computer science)", "software", and "assembly language" were not vocabulary words in the mid 1800s. Timhowardriley (talk) 17:57, 1 November 2015 (UTC)::Terminology aside, I read that as a somewhat awkward statement that the machine would have been useless without software.  It make more sense if you drop the “since”.  Rwessel (talk) 18:08, 1 November 2015 (UTC)References addedI have added the references Collier1970 and Bromley1982 (Bromley1998 is a reprint of Bromley1982). Some statements in this article can be verified by this sources. --Special:Contributions/84.119.110.166|84.119.110.166 (talk) 18:07, 23 December 2015 (UTC) --Special:Contributions/84.119.110.166|84.119.110.166 (talk) 18:47, 23 December 2015 (UTC)